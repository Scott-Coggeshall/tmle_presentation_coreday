<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Trgeted Maximum Likelihood Estimation for Robust Causal Inference</title>
    <meta charset="utf-8" />
    <meta name="author" content="Scott Coggeshall" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Trgeted Maximum Likelihood Estimation for Robust Causal Inference
]
.subtitle[
## üéØ
]
.author[
### Scott Coggeshall
]
.institute[
### Seattle COIN
]
.date[
### April 3rd, 2024
]

---






---
## Introduction

--

#### Targeted maximum likelihood estimation (TMLE) - What is it?

--

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; -an alternative to standard statistical modeling

--

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; -a way to get robust estimates of causal effects using machine learning (ML)

--

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; - some crazy stats wizardry

--

#### What this talk is
--

- a starting point for a deeper dive into TMLE methodology

--

- a chance to see how to apply machine learning in your statistical analyses

--

#### What this talk is NOT

--

- an in-depth look into the math behind TMLE or ML

--

- a rant about how things MUST be done


---
class:  center, middle

## Mark van der Laan, TMLE guru
![](mark_van_der_laan.jpeg)


--

##.b.i[Really] dislikes current statistical practice

---

## Current statistical practice

--

- Check what type of outcome we have

--

 - Continuous? Fit a linear regression.
 
--

 - Binary? Fit a logistic regression.
 
--

 - Survival? Fit a Cox regression.

--

- Focus on whatever effects can be estimated from that model

--

 - Linear regression? mean difference
 
--

 - Logistic regression? Odds ratio!
 
--
 
 - Cox regression? Hazard ratio (whatever that actually is...)


--
 
- Confounders?

--

 - Adjust using main effects terms
 
--

 - MAYBE an interaction or two
--

---
## Current statistical practice

Lots of parametric modeling with main effects 

--

$$
`\begin{align*}
E[Y \mid X, W ] &amp;= \beta_0 + \beta_1 X + \beta_2 W + ...
\end{align*}`
$$

--

$$
`\begin{align*}
logit(P(Y | X, W, ...)) &amp;= \alpha_0 + \alpha_1 x + \alpha_2 W + ...
\end{align*}`
$$

--

What's wrong with this?

--

### .red.b.tt-l[MODEL MISSPECIFICATION!]

--

Parametric models are "small" - highly likely to be wrong

--

‚ùå Missing interactions

--

‚ùå Missing non-linearities


---
class:inverse, center, middle

![](images.jpeg)

&gt; "All models are wrong, but some are useful" 
&gt;      
&gt; \- George E.P. Box

---
![](mark_van_der_laan2.jpeg.png)



---

--
![](simple_dag-1.png)

--

"Wrong but useful" might apply here

--

&lt;img src="complicated_dag.jpeg" width="45%" /&gt;

--

Less likely to apply here
---
# If we can't fit parametric models...
--
what are we supposed to do instead?

--

![](mark_van_der_laan3.jpeg.png)

---
## Statistical Practice *Reformed*

*Start* by specifying the statistical/causal parameter of interest

--

Identify the components of the data generating process (DGP) needed to estimate that parameter

--

Estimate those components and the parameter of interest using minimal *realistic* assumptions about the DGP

--

Machine learning algorithms could work for this...

--

...but they don't come with statistical guarantees

--

### This is where .b.red[TMLE] comes in!




---
## TMLE in Broad Strokes

--

Step 1. Start with a causal parameter of interest (call it `\(\Psi\)`) defined *without* reference to any parametric statistical model

--

Step 2. Identify the portion of the DGP necessary to identify the causal parameter of interest (call this `\(Q\)`)

--

Step 3. Obtain an initial estimate of `\(Q\)` (call it `\(\hat{Q}\)`) using a large statistical model likely to contain the true DGP


--

Step 4. Update `\(\hat{Q}\)` in a way that's *targeted* towards getting an optimal estimate of `\(\Psi\)`

--

Step 5. Calculate point estimates, confidence intervals, and p-values based on asymptotic normality
---
## TMLE Example - Estimating a Mean Difference

--

Step 1. *Counterfactual* mean difference `\(E[Y(1)] - E[Y(0)]\)`

--

Step 2. The *conditional* mean

$$
`\begin{align*}
E[Y | A, W]
\end{align*}`
$$



---
## TMLE Example - Estimating a Mean Difference


Step 1. *Counterfactual* mean difference `\(E[Y(1)] - E[Y(0)]\)`


Step 2. The *conditional* mean

$$
`\begin{align*}
\underbrace{E[Y | A, W]}_{\text{Hit this with machine learning}}
\end{align*}`
$$
--

Step 3. Estimate `\(\hat{E}[Y | A, W]\)` of `\(E[Y | A, W]\)` using the SuperLearner


--

Step 4. Update 

$$
`\begin{align*}
\hat{E}[Y | A, W] \rightarrow\tilde{E}[Y | A, W]
\end{align*}`
$$



---
## TMLE Example - Estimating a Mean Difference


Step 1. *Counterfactual* mean difference `\(E[Y(1)] - E[Y(0)]\)`


Step 2. The *conditional* mean

$$
`\begin{align*}
\underbrace{E[Y | A, W]}_{\text{Hit this with machine learning}}
\end{align*}`
$$

Step 3. Estimate `\(\hat{E}[Y | A, W]\)` of `\(E[Y | A, W]\)` using the SuperLearner

Step 4. Update 

$$
`\begin{align*}
\underbrace{\hat{E}[Y | A, W] \rightarrow\tilde{E}[Y | A, W]}_{\text{This is where the TMLE magic happens}}
\end{align*}`
$$


---
## TMLE Example - Estimating a Mean Difference

Step 4. Update 

$$
`\begin{align*}
\underbrace{\hat{E}[Y | A, W] \rightarrow\tilde{E}[Y | A, W]}_{\text{This is where the TMLE magic happens}}
\end{align*}`
$$

--

Calculate estimated counterfactual mean as 

$$
\frac{1}{n} \sum_{i = 1}^n \tilde{E}[Y_i | A = 1, W_i] - \tilde{E}[Y_i | A = 0, W_i]
$$
--

Step 5. Calculate confidence intervals, p-values etc using efficient influence function (more TMLE magic), or bootstrap

---
## SuperLearner - Putting the ML into TMLE

--

*Which* ML algorithm should we use?

--

&lt;img src="ml_word_cloud.png" width="80%" /&gt;


---
## SuperLearner - Putting the ML into TMLE

--

Ensemble learning, aka the SuperLearner, has an elegant solution:

--

![](bring-me-everyone-gary-oldman.gif)


--

Fit multiple ML algorithms 

--

Use cross-validation to sort them out

--

Pick the best one, or take a weighted average of them all
---
## TMLE - a simulated example

--

Suppose we have data `\((Y, A, W_1, W_2, W_3, W_4)\)` from an observational study

--

`\(W_1, W_2\)` - binary confounders

`\(W_3, W_4\)` - continuous confounder

--

`\(A\)` - **confounded** exposure indicator

--

$$
`\begin{align*}
P(A | W_1, W_2, W_3) &amp;= logit^{-1}(-0.2 + 1.2 * W_2 + log(W_3) + 0.3 * W_1 \times W_4) 
\end{align*}`
$$

--

`\(Y\)` - continuous outcome based on mean model

$$
`\begin{align*}
E[Y | A, W_1, W_2, W_3, W_4] &amp;= 1 + A + W_1 + W_2 + \\
&amp;\qquad A \times W_1 + A \times W_2^2 + A \times W_3 \times W_2
\end{align*}`
$$
---
## TMLE - a simulated example


--

Generate 1000 datasets of size `\(n = 1000\)` based on this DGP

--

For each dataset, estimate the effect of the exposure `\(A\)` in terms of mean difference in outcome `\(Y\)`, adjusting for confounders `\(\boldsymbol{W}\)`

--

Two methods:

--

- Main effects linear regression 

--

- `\(E[Y | A, W] = \beta_0 + \beta_1 A + \beta_2 W_1 + \beta_3 W_2 + \beta_4 W_3 + \beta_5 W_4\)`

--

- TMLE with SuperLearner
  - Random forest, multivariate adaptive regression splines, LASSO





---
.white[Main effects linear regression is biased...]
.white[...but TMLE with SuperLearner does much better]

![](base_plot.png)
---
.blue[Main effects linear regression] is biased...
.white[...but TMLE with SuperLearner does much better]

![](linear_regression_only_plot.png)
---
.blue[Main effects linear regression] is biased...
but .gold[TMLE with SuperLearner] does much better

![](combined_plot.png)


---
# Wrapping Up

--

TMLE offers a robust alternative to standard approaches to regression modeling

--

Leverages machine learning, but comes with statistical guarantees

--

Computationally intensive compared to parametric models

--

May not make a difference in some datasets


---



# Additional Resources

## Summer Institutes - UW Biostat
(https://si.biostat.washington.edu/institutes/siscer)

*Modern Statistical Learning for Observational Data* 
(https://si.biostat.washington.edu/institutes/siscer/CR2408)

## Books

*Targeted Learning* by Mark van der Laan and Sherri Rose
(https://link.springer.com/book/10.1007/978-1-4419-9782-1)


---
# Additional Resources

## Websites

*An Illustrated Guide to TMLE* by Katherine Hoffman
(https://www.khstats.com/blog/tmle/tutorial)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
